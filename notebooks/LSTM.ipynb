{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a50ecd-28c5-40ce-9921-c518bca3cd3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-04 18:04:23.337319: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/shivankpandey/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - accuracy: 0.5641 - loss: 0.6892 - val_accuracy: 0.5872 - val_loss: 0.6805\n",
      "Epoch 2/30\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5137 - loss: 0.6878 - val_accuracy: 0.5872 - val_loss: 0.6823\n",
      "Epoch 3/30\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5395 - loss: 0.6926 - val_accuracy: 0.5872 - val_loss: 0.6806\n",
      "Epoch 4/30\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5825 - loss: 0.6812 - val_accuracy: 0.5872 - val_loss: 0.6852\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step\n",
      "LSTM Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        45\n",
      "           1       0.59      1.00      0.74        64\n",
      "\n",
      "    accuracy                           0.59       109\n",
      "   macro avg       0.29      0.50      0.37       109\n",
      "weighted avg       0.34      0.59      0.43       109\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 0 45]\n",
      " [ 0 64]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shivankpandey/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/shivankpandey/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/shivankpandey/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "LSTM.py - LSTM model training using SPY technical indicators + sentiment + cyclic date features.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# === File Paths ===\n",
    "PROJECT_ROOT = Path(__file__).resolve().parents[2]\n",
    "PROCESSED_DATA = PROJECT_ROOT / \"data\" / \"processed\" / \"spy_with_sentiment.csv\"\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(PROCESSED_DATA)\n",
    "\n",
    "# Ensure datetime format\n",
    "if \"date\" in df.columns:\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "else:\n",
    "    df[\"date\"] = pd.to_datetime(df[\"timestamp\"])\n",
    "\n",
    "# Create target\n",
    "df[\"Target\"] = (df[\"close\"].shift(-1) > df[\"close\"]).astype(int)\n",
    "\n",
    "# Fill missing sentiment values BEFORE dropping\n",
    "sentiment_cols = [\"positive\", \"neutral\", \"negative\", \"compound\", \"headline_count\"]\n",
    "df[sentiment_cols] = df[sentiment_cols].fillna(0)\n",
    "\n",
    "# Cyclic encoding for day of week and month\n",
    "df[\"day_of_week\"] = df[\"date\"].dt.dayofweek\n",
    "df[\"month\"] = df[\"date\"].dt.month\n",
    "df[\"dow_sin\"] = np.sin(2 * np.pi * df[\"day_of_week\"] / 7)\n",
    "df[\"dow_cos\"] = np.cos(2 * np.pi * df[\"day_of_week\"] / 7)\n",
    "df[\"month_sin\"] = np.sin(2 * np.pi * df[\"month\"] / 12)\n",
    "df[\"month_cos\"] = np.cos(2 * np.pi * df[\"month\"] / 12)\n",
    "\n",
    "# Drop only rows missing essential values\n",
    "df.dropna(subset=[\"close\", \"Target\"], inplace=True)\n",
    "\n",
    "# Features list\n",
    "features = [\n",
    "    \"close\", \"volume\", \"EMA_50\", \"EMA_200\",\n",
    "    \"RSI_14\", \"MACD\", \"MACD_Signal\", \"MACD_Hist\",\n",
    "    \"Close_Lag_1\", \"Volume_Lag_1\", \"RSI_Lag_1\",\n",
    "    \"MA_5\", \"MA_10\", \"Volatility_5\",\n",
    "    \"positive\", \"neutral\", \"negative\", \"compound\", \"headline_count\",\n",
    "    \"dow_sin\", \"dow_cos\", \"month_sin\", \"month_cos\"\n",
    "]\n",
    "\n",
    "X = df[features]\n",
    "y = df[\"Target\"]\n",
    "\n",
    "# Scale features\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Sequence builder\n",
    "def create_sequences(X, y, time_steps=10):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        Xs.append(X[i:i + time_steps])\n",
    "        ys.append(y[i + time_steps])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "X_seq, y_seq = create_sequences(X_scaled, y.values)\n",
    "\n",
    "# Train/test split\n",
    "split = int(0.8 * len(X_seq))\n",
    "X_train, X_test = X_seq[:split], X_seq[split:]\n",
    "y_train, y_test = y_seq[:split], y_seq[split:]\n",
    "\n",
    "# Build LSTM model\n",
    "model = Sequential([\n",
    "    LSTM(128, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    Dropout(0.3),\n",
    "    LSTM(64),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train model\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True)\n",
    "model.fit(X_train, y_train, epochs=30, batch_size=32,\n",
    "          validation_data=(X_test, y_test), callbacks=[early_stop], verbose=1)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
    "print(\"LSTM Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
